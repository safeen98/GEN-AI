{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12c8ee5b",
   "metadata": {},
   "source": [
    "## Building A Chatbot\n",
    "We'll go over an example of how to design and implement an LLM-powered chatbot. This chatbot will be able to have a conversation and remember previous interactions.\n",
    "\n",
    "Note that this chatbot that we build will only use the language model to have a conversation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b73f588",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb9704cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model = ChatGroq(model = \"llama-3.3-70b-versatile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "579740b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Safeen Khan! It's nice to meet you. Accenture is a well-known and respected company, so that's great that you're a part of their team. What do you do at Accenture, if you don't mind me asking? Are you working on any exciting projects or initiatives?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 62, 'prompt_tokens': 48, 'total_tokens': 110, 'completion_time': 0.182112131, 'prompt_time': 0.002139561, 'queue_time': 0.055247258, 'total_time': 0.184251692}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_155ab82e98', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--d1387737-47cd-4539-a554-3f09bf4e2ac7-0', usage_metadata={'input_tokens': 48, 'output_tokens': 62, 'total_tokens': 110})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "model.invoke([HumanMessage(content=\"Hello my name is Safeen Khan and I work at Accenture\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd84358d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Safeen Khan, and you work at Accenture.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 128, 'total_tokens': 143, 'completion_time': 0.031910061, 'prompt_time': 0.006805959, 'queue_time': 0.0536388, 'total_time': 0.03871602}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_9e1e8f8435', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--9b795353-f551-46b9-bf51-d0bb49e43703-0', usage_metadata={'input_tokens': 128, 'output_tokens': 15, 'total_tokens': 143})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hello my name is Safeen Khan and I work at Accenture\"),\n",
    "        AIMessage(content = \"Hello Safeen Khan! It's nice to meet you. Accenture is a well-known and respected company, so that's great that you're a part of their team. What do you do at Accenture, if you don't mind me asking? Are you working on any exciting projects or initiatives?\"),\n",
    "        HumanMessage(content = \"What is my name and where do I work\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb98c639",
   "metadata": {},
   "source": [
    "We can see the model has some history and can remember the content that we have told"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83242b9b",
   "metadata": {},
   "source": [
    "### Message History\n",
    "We can use a Message History class to wrap our model and make it stateful. This will keep track of inputs and outputs of the model, and store them in some datastore. Future interactions will then load those messages and pass them into the chain as part of the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b38440eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {}\n",
    "def get_session_history(session_id : str) ->BaseChatMessageHistory:    #BaseChatMessageHistory is the return type\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(model,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6a8b81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\":{\n",
    "    \"session_id\" : \"chat1\"\n",
    "}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db2f1ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hello my name is Safeen Khan and I work at Accenture\")],\n",
    "    config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a602aa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Safeen Khan! It's nice to meet you. Welcome to our conversation. Accenture is a well-known and respected company, what do you do there? Are you working on any exciting projects or initiatives? I'd love to hear more about your role and experiences.\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf6caaaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Safeen Khan, and you work at Accenture.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"what is my name ?\")],\n",
    "    config = config)\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dca8ead",
   "metadata": {},
   "source": [
    "Now if we change the config or main the session_id we will se it doen't remembers my name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b35fb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "config2 = {\"configurable\":{\n",
    "    \"session_id\":\"chat2\"\n",
    "}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4bf3de70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't know your name. I'm a large language model, I don't have any information about you, including your name. Our conversation just started, and I don't have any prior knowledge about you. If you'd like to share your name, I'd be happy to chat with you!\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"what is my name ?\")],\n",
    "    config = config2\n",
    ")\n",
    "response.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
